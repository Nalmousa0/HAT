{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LA6OcREag_C",
        "outputId": "235296d9-40aa-4a55-a4df-c3570a333b35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.31.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyvNdFUjdLYv",
        "outputId": "e0ab222a-8513-4d66-fef1-3408a6875c39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/1.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndBCEcdUdRfB",
        "outputId": "6782ae64-3859-42af-ad7a-c82d4345db60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/880.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/880.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2023.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.3.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.66.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895240 sha256=5ebd5652c20956e0bfd79b2ffed81effc98ab480bc1bfc2dca6456f800d2a917\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.0.53\n"
          ]
        }
      ],
      "source": [
        "!pip install sacremoses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DajRx7zfaXI2"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import MarianMTModel, MarianTokenizer, AdamW\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import sacremoses\n",
        "import sentencepiece\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iFr1-6n7aXI5"
      },
      "outputs": [],
      "source": [
        "# Load your parallel corpus data into a pandas DataFrame\n",
        "data = pd.read_csv(\"data_without_hadith.csv\", index_col=0)  # Adapt the file name and structure\n",
        "\n",
        "# Define your fine-tuning dataset class\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer):\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        source_text = self.data.iloc[idx][\"English\"]\n",
        "        target_text = self.data.iloc[idx][\"Arabic\"]\n",
        "\n",
        "        # Tokenize source and target sentences\n",
        "        source_tokens = self.tokenizer.encode(source_text, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "        with self.tokenizer.as_target_tokenizer():\n",
        "          target_tokens = self.tokenizer.encode(target_text, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": source_tokens.squeeze(),\n",
        "            \"attention_mask\": source_tokens.squeeze().gt(0),  # Create attention mask\n",
        "            \"labels\": target_tokens.squeeze(),\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DyvMR15gJx-O"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "EwMJCOwxaXI7",
        "outputId": "f8d68011-ca10-48d9-a0a7-7b67849f108f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  Arabic  \\\n",
              "0                           تفريج الكروب فى تدبير الحروب   \n",
              "1                                                  مقدمة   \n",
              "2      بسم الله الرحمن الرحيم.. مؤيد الإسلام من سلطان...   \n",
              "3      ومسعد جده العالى بإبادة أعدائه الطغاة المارقين...   \n",
              "4      وأشهد أن لا إله إلا الله وحده لا شريك له، شهاد...   \n",
              "...                                                  ...   \n",
              "61728  وقال المأموني في تاريخه: وقيل إن أهل المدينة ع...   \n",
              "61729  ثم إن كل من بين مكة والمدينة ممن قرب من البصرة...   \n",
              "61730  قلت: وذكر كشاجم في كتاب المصايد والمطارد” أن ا...   \n",
              "61731  حدثنا أبو بكر بن أبي شيبة، حدثنا أسود بن عامر،...   \n",
              "61732  حدثنا الحسن بن عرفة، حدثنا عمار بن محمد، عن ال...   \n",
              "\n",
              "                                                 English  \n",
              "0      TAFRIJ AL-KURUB FI TADBIR AL-HURUBA Muslim Man...  \n",
              "1                                           INTRODUCTION  \n",
              "2      IN THE NAME OF GOD, THE MERCIFUL, THE COMPASSI...  \n",
              "3      And [he is] the cause of his noble sire’s happ...  \n",
              "4      I declare that there is no god but God alone, ...  \n",
              "...                                                  ...  \n",
              "61728  Al-Mamuni says, in his History: “It is stated ...  \n",
              "61729  Then, all who dwelt between Mecca and Medina, ...  \n",
              "61730  Kushajim says, in his work entitled Al-Masaid ...  \n",
              "61731  “I heard the Prophet(ﷺ) say: ‘One of the porte...  \n",
              "61732  “The Hour will not begin until you fight peopl...  \n",
              "\n",
              "[61733 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-fc28c08f-c9f2-49a6-813f-f86903484e22\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Arabic</th>\n",
              "      <th>English</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>تفريج الكروب فى تدبير الحروب</td>\n",
              "      <td>TAFRIJ AL-KURUB FI TADBIR AL-HURUBA Muslim Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>مقدمة</td>\n",
              "      <td>INTRODUCTION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>بسم الله الرحمن الرحيم.. مؤيد الإسلام من سلطان...</td>\n",
              "      <td>IN THE NAME OF GOD, THE MERCIFUL, THE COMPASSI...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ومسعد جده العالى بإبادة أعدائه الطغاة المارقين...</td>\n",
              "      <td>And [he is] the cause of his noble sire’s happ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>وأشهد أن لا إله إلا الله وحده لا شريك له، شهاد...</td>\n",
              "      <td>I declare that there is no god but God alone, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61728</th>\n",
              "      <td>وقال المأموني في تاريخه: وقيل إن أهل المدينة ع...</td>\n",
              "      <td>Al-Mamuni says, in his History: “It is stated ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61729</th>\n",
              "      <td>ثم إن كل من بين مكة والمدينة ممن قرب من البصرة...</td>\n",
              "      <td>Then, all who dwelt between Mecca and Medina, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61730</th>\n",
              "      <td>قلت: وذكر كشاجم في كتاب المصايد والمطارد” أن ا...</td>\n",
              "      <td>Kushajim says, in his work entitled Al-Masaid ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61731</th>\n",
              "      <td>حدثنا أبو بكر بن أبي شيبة، حدثنا أسود بن عامر،...</td>\n",
              "      <td>“I heard the Prophet(ﷺ) say: ‘One of the porte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61732</th>\n",
              "      <td>حدثنا الحسن بن عرفة، حدثنا عمار بن محمد، عن ال...</td>\n",
              "      <td>“The Hour will not begin until you fight peopl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>61733 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc28c08f-c9f2-49a6-813f-f86903484e22')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-3436cf27-e92d-484a-a830-1251fdaec9ac\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3436cf27-e92d-484a-a830-1251fdaec9ac')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-3436cf27-e92d-484a-a830-1251fdaec9ac button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fc28c08f-c9f2-49a6-813f-f86903484e22 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fc28c08f-c9f2-49a6-813f-f86903484e22');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nithPy_qTdB-",
        "outputId": "a084578f-7dc1-4288-87b2-ffd8c191d229"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rgX0x1zK4za4"
      },
      "outputs": [],
      "source": [
        "# Load pretrained model and tokenizer for Arabic to English translation\n",
        "model_name = \"Helsinki-NLP/opus-mt-en-ar\"\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained('/content/drive/MyDrive/first_model').to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9iJdriiaXI9",
        "outputId": "16af9559-5658-4213-aa28-157c65ed4316"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Create fine-tuning dataset and dataloader\n",
        "train_dataset = TranslationDataset(data, tokenizer)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSq9OCnijJCr",
        "outputId": "b8137326-8dd9-484a-a8ea-03e51f523cae"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vULQdBVqaXI_",
        "outputId": "03a71ae3-2844-40a4-b5c5-376561568d96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3] - Batch Loss: 0.2335\n",
            "Epoch [1/3] - Batch Loss: 0.2298\n",
            "Epoch [1/3] - Batch Loss: 0.2736\n",
            "Epoch [1/3] - Batch Loss: 0.1906\n",
            "Epoch [1/3] - Batch Loss: 0.1655\n",
            "Epoch [1/3] - Batch Loss: 0.1460\n",
            "Epoch [1/3] - Batch Loss: 0.2521\n",
            "Epoch [1/3] - Batch Loss: 0.2256\n",
            "Epoch [1/3] - Batch Loss: 0.1377\n",
            "Epoch [1/3] - Batch Loss: 0.2975\n",
            "Epoch [1/3] - Batch Loss: 0.1858\n",
            "Epoch [1/3] - Batch Loss: 0.2505\n",
            "Epoch [1/3] - Batch Loss: 0.2289\n",
            "Epoch [1/3] - Batch Loss: 0.2480\n",
            "Epoch [1/3] - Batch Loss: 0.2809\n",
            "Epoch [1/3] - Batch Loss: 0.1861\n",
            "Epoch [1/3] - Batch Loss: 0.1552\n",
            "Epoch [1/3] - Batch Loss: 0.2442\n",
            "Epoch [1/3] - Batch Loss: 0.3036\n",
            "Epoch [1/3] - Batch Loss: 0.2207\n",
            "Epoch [1/3] - Batch Loss: 0.1262\n",
            "Epoch [1/3] - Batch Loss: 0.2442\n",
            "Epoch [1/3] - Batch Loss: 0.2573\n",
            "Epoch [1/3] - Batch Loss: 0.2408\n",
            "Epoch [1/3] - Batch Loss: 0.3372\n",
            "Epoch [1/3] - Batch Loss: 0.3412\n",
            "Epoch [1/3] - Batch Loss: 0.1750\n",
            "Epoch [1/3] - Batch Loss: 0.3841\n",
            "Epoch [1/3] - Batch Loss: 0.3510\n",
            "Epoch [1/3] - Batch Loss: 0.1026\n",
            "Epoch [1/3] - Batch Loss: 0.2038\n",
            "Epoch [1/3] - Batch Loss: 0.1991\n",
            "Epoch [1/3] - Batch Loss: 0.2055\n",
            "Epoch [1/3] - Batch Loss: 0.2446\n",
            "Epoch [1/3] - Batch Loss: 0.2312\n",
            "Epoch [1/3] - Batch Loss: 0.3533\n",
            "Epoch [1/3] - Batch Loss: 0.1794\n",
            "Epoch [1/3] - Batch Loss: 0.2788\n",
            "Epoch [1/3] - Batch Loss: 0.2433\n",
            "Epoch [1/3] - Batch Loss: 0.3296\n",
            "Epoch [1/3] - Batch Loss: 0.2764\n",
            "Epoch [1/3] - Batch Loss: 0.1828\n",
            "Epoch [1/3] - Batch Loss: 0.2724\n",
            "Epoch [1/3] - Batch Loss: 0.2890\n",
            "Epoch [1/3] - Batch Loss: 0.1498\n",
            "Epoch [1/3] - Batch Loss: 0.1590\n",
            "Epoch [1/3] - Batch Loss: 0.2272\n",
            "Epoch [1/3] - Batch Loss: 0.2082\n",
            "Epoch [1/3] - Batch Loss: 0.2242\n",
            "Epoch [1/3] - Batch Loss: 0.2951\n",
            "Epoch [1/3] - Batch Loss: 0.1758\n",
            "Epoch [1/3] - Batch Loss: 0.2115\n",
            "Epoch [1/3] - Batch Loss: 0.3034\n",
            "Epoch [1/3] - Batch Loss: 0.0879\n",
            "Epoch [1/3] - Batch Loss: 0.1864\n",
            "Epoch [1/3] - Batch Loss: 0.1173\n",
            "Epoch [1/3] - Batch Loss: 0.2900\n",
            "Epoch [1/3] - Batch Loss: 0.1935\n",
            "Epoch [1/3] - Batch Loss: 0.2461\n",
            "Epoch [1/3] - Batch Loss: 0.2532\n",
            "Epoch [1/3] - Batch Loss: 0.2609\n",
            "Epoch [1/3] - Batch Loss: 0.2176\n",
            "Epoch [1/3] - Batch Loss: 0.1646\n",
            "Epoch [1/3] - Batch Loss: 0.2385\n",
            "Epoch [1/3] - Batch Loss: 0.1399\n",
            "Epoch [1/3] - Batch Loss: 0.2555\n",
            "Epoch [1/3] - Batch Loss: 0.3412\n",
            "Epoch [1/3] - Batch Loss: 0.3157\n",
            "Epoch [1/3] - Batch Loss: 0.1745\n",
            "Epoch [1/3] - Batch Loss: 0.2291\n",
            "Epoch [1/3] - Batch Loss: 0.2951\n",
            "Epoch [1/3] - Batch Loss: 0.1506\n",
            "Epoch [1/3] - Batch Loss: 0.2379\n",
            "Epoch [1/3] - Batch Loss: 0.1469\n",
            "Epoch [1/3] - Batch Loss: 0.3896\n",
            "Epoch [1/3] - Batch Loss: 0.2544\n",
            "Epoch [1/3] - Batch Loss: 0.1622\n",
            "Epoch [1/3] - Batch Loss: 0.3052\n",
            "Epoch [1/3] - Batch Loss: 0.2090\n",
            "Epoch [1/3] - Batch Loss: 0.1104\n",
            "Epoch [1/3] - Batch Loss: 0.2910\n",
            "Epoch [1/3] - Batch Loss: 0.2054\n",
            "Epoch [1/3] - Batch Loss: 0.1325\n",
            "Epoch [1/3] - Batch Loss: 0.1739\n",
            "Epoch [1/3] - Batch Loss: 0.1512\n",
            "Epoch [1/3] - Batch Loss: 0.2985\n",
            "Epoch [1/3] - Batch Loss: 0.2306\n",
            "Epoch [1/3] - Batch Loss: 0.2502\n",
            "Epoch [1/3] - Batch Loss: 0.2429\n",
            "Epoch [1/3] - Batch Loss: 0.3019\n",
            "Epoch [1/3] - Batch Loss: 0.2070\n",
            "Epoch [1/3] - Batch Loss: 0.2181\n",
            "Epoch [1/3] - Batch Loss: 0.2834\n",
            "Epoch [1/3] - Batch Loss: 0.3050\n",
            "Epoch [1/3] - Batch Loss: 0.2586\n",
            "Epoch [1/3] - Batch Loss: 0.2355\n",
            "Epoch [1/3] - Batch Loss: 0.1732\n",
            "Epoch [1/3] - Batch Loss: 0.1103\n",
            "Epoch [1/3] - Batch Loss: 0.2317\n",
            "Epoch [1/3] - Batch Loss: 0.2094\n",
            "Epoch [1/3] - Batch Loss: 0.1635\n",
            "Epoch [1/3] - Batch Loss: 0.1801\n",
            "Epoch [1/3] - Batch Loss: 0.1606\n",
            "Epoch [1/3] - Batch Loss: 0.2588\n",
            "Epoch [1/3] - Batch Loss: 0.2489\n",
            "Epoch [1/3] - Batch Loss: 0.2097\n",
            "Epoch [1/3] - Batch Loss: 0.2168\n",
            "Epoch [1/3] - Batch Loss: 0.3205\n",
            "Epoch [1/3] - Batch Loss: 0.2135\n",
            "Epoch [1/3] - Batch Loss: 0.1854\n",
            "Epoch [1/3] - Batch Loss: 0.1262\n",
            "Epoch [1/3] - Batch Loss: 0.2087\n",
            "Epoch [1/3] - Batch Loss: 0.2216\n",
            "Epoch [1/3] - Batch Loss: 0.2560\n",
            "Epoch [1/3] - Batch Loss: 0.1812\n",
            "Epoch [1/3] - Batch Loss: 0.1349\n",
            "Epoch [1/3] - Batch Loss: 0.2966\n",
            "Epoch [1/3] - Batch Loss: 0.3140\n",
            "Epoch [1/3] - Batch Loss: 0.2218\n",
            "Epoch [1/3] - Batch Loss: 0.2517\n",
            "Epoch [1/3] - Batch Loss: 0.1658\n",
            "Epoch [1/3] - Batch Loss: 0.2738\n",
            "Epoch [1/3] - Batch Loss: 0.1606\n",
            "Epoch [1/3] - Batch Loss: 0.2464\n",
            "Epoch [1/3] - Batch Loss: 0.3538\n",
            "Epoch [1/3] - Batch Loss: 0.2558\n",
            "Epoch [1/3] - Batch Loss: 0.2652\n",
            "Epoch [1/3] - Batch Loss: 0.2418\n",
            "Epoch [1/3] - Batch Loss: 0.1300\n",
            "Epoch [1/3] - Batch Loss: 0.2113\n",
            "Epoch [1/3] - Batch Loss: 0.3576\n",
            "Epoch [1/3] - Batch Loss: 0.2654\n",
            "Epoch [1/3] - Batch Loss: 0.2463\n",
            "Epoch [1/3] - Batch Loss: 0.1217\n",
            "Epoch [1/3] - Batch Loss: 0.3893\n",
            "Epoch [1/3] - Batch Loss: 0.3140\n",
            "Epoch [1/3] - Batch Loss: 0.2812\n",
            "Epoch [1/3] - Batch Loss: 0.2949\n",
            "Epoch [1/3] - Batch Loss: 0.3076\n",
            "Epoch [1/3] - Batch Loss: 0.2102\n",
            "Epoch [1/3] - Batch Loss: 0.1295\n",
            "Epoch [1/3] - Batch Loss: 0.2371\n",
            "Epoch [1/3] - Batch Loss: 0.1510\n",
            "Epoch [1/3] - Batch Loss: 0.1525\n",
            "Epoch [1/3] - Batch Loss: 0.2776\n",
            "Epoch [1/3] - Batch Loss: 0.1491\n",
            "Epoch [1/3] - Batch Loss: 0.1786\n",
            "Epoch [1/3] - Batch Loss: 0.2404\n",
            "Epoch [1/3] - Batch Loss: 0.3788\n",
            "Epoch [1/3] - Batch Loss: 0.1880\n"
          ]
        }
      ],
      "source": [
        "\n",
        "num_epochs = 3\n",
        "best_loss = float('inf')  # Initialize with a high value\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}] - Batch Loss: {loss.item():.4f}')\n",
        "\n",
        "    average_loss = total_loss / len(train_dataloader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Average Loss: {average_loss:.4f}\")\n",
        "\n",
        "    # Save the best model based on training loss\n",
        "    if average_loss < best_loss:\n",
        "        best_loss = average_loss\n",
        "        model.save_pretrained(\"seconed_model\")\n",
        "        model.save_pretrained('/content/drive/My Drive/seconed_model')\n",
        "\n",
        "print(\"Training finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZdRM8mhw4za6"
      },
      "outputs": [],
      "source": [
        "stock_model = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-en-ar').to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hunain_model = MarianMTModel.from_pretrained('/content/drive/MyDrive/first_model').to(device)"
      ],
      "metadata": {
        "id": "7wrQcI2fiB6C"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference function\n",
        "def translate_english_to_arabic_stock(input_text):\n",
        "    input_text = [input_text]\n",
        "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
        "    translated_ids = stock_model.generate(input_ids, max_length=len(str(input_text))+10,num_beams=100).to(device)\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "      translated_text = tokenizer.decode(translated_ids[0], skip_special_tokens=True)\n",
        "    return translated_text"
      ],
      "metadata": {
        "id": "FPzNA5H6m8kZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference function\n",
        "def translate_english_to_arabic_hunain(input_text):\n",
        "    input_text = [input_text]\n",
        "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
        "    translated_ids = model.generate(input_ids, max_length=len(str(input_text))+10,num_beams=100).to(device)\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "      translated_text = tokenizer.decode(translated_ids[0], skip_special_tokens=True)\n",
        "    return translated_text"
      ],
      "metadata": {
        "id": "ZJd6_Ox-plNu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def split_text_into_lines(text, max_words_per_line=100):\n",
        "    words = text.split()\n",
        "    lines = []\n",
        "    current_line = []\n",
        "\n",
        "    for word in words:\n",
        "        if len(' '.join(current_line + [word])) <= max_words_per_line:\n",
        "            current_line.append(word)\n",
        "        else:\n",
        "            lines.append(' '.join(current_line))\n",
        "            current_line = [word]\n",
        "\n",
        "    if current_line:\n",
        "        lines.append(' '.join(current_line))\n",
        "\n",
        "    return lines\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MNwx7W59aaqf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example usage\n",
        "input_text =  \"The concept of beauty is multifaceted and often subjective.\"\n",
        "translated_text = translate_english_to_arabic_stock(input_text)\n",
        "\n",
        "input_lines = split_text_into_lines(input_text)\n",
        "translated_lines = split_text_into_lines(translated_text)\n",
        "\n",
        "print(\"Input:\")\n",
        "for line in input_lines:\n",
        "    print(line)\n",
        "\n",
        "print(\"\\nTranslated:\")\n",
        "for line in translated_lines:\n",
        "    print(u'{}'.format(line))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-J7DT6TupeZR",
        "outputId": "29e7086a-acd0-4ba0-919d-25f448a46ec3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            "The concept of beauty is multifaceted and often subjective.\n",
            "\n",
            "Translated:\n",
            "ومفهوم الجمال هو مفهوم متعدد الأوجه وذوي في كثير من الأحيان.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6IR-VOvvaXJC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c99cfadc-e387-489b-a935-dc396448246b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            "The concept of beauty is multifaceted and often subjective.\n",
            "\n",
            "Translated:\n",
            "ومفهوم الحسن هو المعاني المتعددة والذاتية في كثير من الأحيان.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Example usage\n",
        "input_text =  \"The concept of beauty is multifaceted and often subjective.\"\n",
        "translated_text = translate_english_to_arabic_hunain(input_text)\n",
        "\n",
        "input_lines = split_text_into_lines(input_text)\n",
        "translated_lines = split_text_into_lines(translated_text)\n",
        "print(\"Input:\")\n",
        "for line in input_lines:\n",
        "    print(line)\n",
        "\n",
        "print(\"\\nTranslated:\")\n",
        "for line in translated_lines:\n",
        "    print(u'{}'.format(line))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfr99Kd1PNLU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb703cc4-5dff-4eee-c964-bae15c999001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Save your model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QQcvDr3KUs8D"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
